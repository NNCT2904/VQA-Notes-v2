{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Variational Quantum Models with Barren Plateaus Mitigation Strategies\n",
    "*Training QNN treated with method 3 (Identity Blocks) of the BP mitigation strategy (Cancer)*\n",
    "\n",
    "**Authors:**\n",
    "- Jacob Cybulski and Thanh Nguyen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.fake_provider import FakeAlmadenV2, FakeSherbrooke\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit.primitives import Estimator, BackendEstimator\n",
    "from qiskit_algorithms.gradients import ParamShiftEstimatorGradient\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from Components.train import *\n",
    "from Components.data import cancer_data\n",
    "from Components.circuits import *\n",
    "from Components.gradients import *\n",
    "from Components.utils import *\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config for all experiments (data size, feature dim etc.) is stored here\n",
    "from GLOBAL_CONFIG import *\n",
    "# Remember to tag the method\n",
    "METHOD_TAG = 'm3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend = FakeSherbrooke()\n",
    "# estimator = BackendEstimator(backend)\n",
    "estimator = Estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 398 samples\n",
      "Testing set: 171 samples\n",
      "Number of features: 4\n",
      "PCA Explained variance: [4.43782605e+05 7.31010006e+03 7.03833742e+02 5.46487379e+01]\n",
      "Classes:[0 1]; Encoded as: [-1  1]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = cancer_data(PCA_n = FEATURE_DIM)\n",
    "# X_train, X_val, y_train, y_val = fetch_mnist(PCA_n = FEATURE_DIM, data_size=DATA_SIZE)\n",
    "# X_train, X_val, y_train, y_val = iris(pd=False, PCA_n=None)\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train).to(torch.float32)\n",
    "y_train_t = torch.from_numpy(y_train).to(torch.float32)\n",
    "X_val_t = torch.from_numpy(X_val).to(torch.float32)\n",
    "y_val_t = torch.from_numpy(y_val).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found save folder: ./Logs-Cancer-v4/m3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (exists(f'{LOG_PATH}/{METHOD_TAG}')):\n",
    "    print(f'Found save folder: {LOG_PATH}/{METHOD_TAG}\\n')\n",
    "else:\n",
    "    makedirs(f'{LOG_PATH}/{METHOD_TAG}')\n",
    "    print(f'Creating save folder: {LOG_PATH}/{METHOD_TAG}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Gradient Variance Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = list(range(2, MAX_QUBITS))\n",
    "\n",
    "# Globak operator for all ansatzes, measure all qubits\n",
    "G_O = [SparsePauliOp.from_list([('Z'*n, 1)]) for n in num_qubits]\n",
    "\n",
    "# Local operator for all ansatzes, measere 2 last qubits\n",
    "L_O = [SparsePauliOp.from_list([('I' * (n - 2)+'Z'*2, 1)]) for n in num_qubits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleM3Var():\n",
    "# Generate the pre-trained circuits\n",
    "    pre_trained_block = [preTrainedBlockGenerator(n, int(np.floor(n/2))) for n in num_qubits]\n",
    "\n",
    "    ansatzes_m3 = []\n",
    "    for i in range(len(pre_trained_block)):\n",
    "        ansatzes_m3.append(pre_trained_block[i]['circuit'])\n",
    "\n",
    "    parameters_m3 = []\n",
    "    for i in range(len(pre_trained_block)):\n",
    "        parameters_m3.append(list(pre_trained_block[i]['params_values'].values()))\n",
    "\n",
    "    gradients_m0 = sampleAnsatz(estimator, ansatzes_m3, G_O, parameters_m3)\n",
    "\n",
    "    variance = getVariance(gradients_m0, num_qubits)\n",
    "    \n",
    "    return variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = featureMapGenerator(FEATURE_DIM)\n",
    "identity_block = preTrainedBlockGenerator(MAX_QUBITS_CLASSIFICATION, MAX_IDENTITIES_BLOCKS, overlay=IDENTITY_BLOCKS_OVERLAY, entanglement=ENTANGLEMENT, insert_barriers=True)\n",
    "ansatz = identity_block['circuit']\n",
    "qc=circuitBuilder(feature_map, ansatz)\n",
    "\n",
    "\n",
    "id_dict = {k.name : v for k, v in identity_block['params_values'].items()}\n",
    "initial_point = [id_dict[p.name] for p in list(ansatz.parameters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CPU'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find what devices are available\n",
    "from qiskit_aer.backends import AerSimulator\n",
    "devices = AerSimulator().available_devices()\n",
    "devices\n",
    "\n",
    "# Force CPU - PyTorch+Qiskit too slow with GPU\n",
    "devices = ('CPU')\n",
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: CPU\n"
     ]
    }
   ],
   "source": [
    "from qiskit.primitives import Estimator # For \"CPU\", ignores device=\"GPU\" option\n",
    "from qiskit_aer.primitives import Estimator as AerEstimator # For device=\"GPU\" option\n",
    "\n",
    "seed = 2023\n",
    "\n",
    "# Use GPU when present, otherwise CPU\n",
    "if 'GPU' in devices:\n",
    "    device = 'GPU'\n",
    "    estimator = AerEstimator(\n",
    "        backend_options={'seed_simulator': seed, 'method': 'statevector', \n",
    "                         'device' : device, 'cuStateVec_enable' : True},\n",
    "        run_options={'seed': seed, 'shots': 1000},\n",
    "        transpile_options={\"seed_transpiler\": seed},\n",
    "    )\n",
    "else:\n",
    "    device = 'CPU'\n",
    "    estimator = Estimator()\n",
    "    estimator.set_options(method='statevector')\n",
    "    estimator.set_options(device=device)\n",
    "    estimator.set_options(seed=seed)\n",
    "    estimator.options\n",
    "\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.992211</td>\n",
       "      <td>-1.458556</td>\n",
       "      <td>-2.522877</td>\n",
       "      <td>-5.227287</td>\n",
       "      <td>-5.570132</td>\n",
       "      <td>-3.687603</td>\n",
       "      <td>-2.891251</td>\n",
       "      <td>-1.200210</td>\n",
       "      <td>-3.843001</td>\n",
       "      <td>-5.680121</td>\n",
       "      <td>...</td>\n",
       "      <td>2.364161</td>\n",
       "      <td>3.452805</td>\n",
       "      <td>3.652766</td>\n",
       "      <td>-3.619643</td>\n",
       "      <td>-3.314694</td>\n",
       "      <td>-2.345685</td>\n",
       "      <td>-1.343511</td>\n",
       "      <td>-1.340704</td>\n",
       "      <td>1.304490</td>\n",
       "      <td>1.016670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.875168</td>\n",
       "      <td>-1.301533</td>\n",
       "      <td>-2.525220</td>\n",
       "      <td>-5.253348</td>\n",
       "      <td>-5.428700</td>\n",
       "      <td>-3.745577</td>\n",
       "      <td>-2.865036</td>\n",
       "      <td>-1.285238</td>\n",
       "      <td>-4.030012</td>\n",
       "      <td>-5.692140</td>\n",
       "      <td>...</td>\n",
       "      <td>2.324138</td>\n",
       "      <td>3.390716</td>\n",
       "      <td>3.693698</td>\n",
       "      <td>-3.592282</td>\n",
       "      <td>-3.355905</td>\n",
       "      <td>-2.350062</td>\n",
       "      <td>-1.397841</td>\n",
       "      <td>-1.332435</td>\n",
       "      <td>1.358238</td>\n",
       "      <td>0.986324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.960074</td>\n",
       "      <td>-1.473065</td>\n",
       "      <td>-2.406000</td>\n",
       "      <td>-5.350232</td>\n",
       "      <td>-5.436769</td>\n",
       "      <td>-3.739717</td>\n",
       "      <td>-2.846821</td>\n",
       "      <td>-1.299774</td>\n",
       "      <td>-4.036907</td>\n",
       "      <td>-5.791673</td>\n",
       "      <td>...</td>\n",
       "      <td>2.349994</td>\n",
       "      <td>3.386184</td>\n",
       "      <td>3.633986</td>\n",
       "      <td>-3.685507</td>\n",
       "      <td>-3.364069</td>\n",
       "      <td>-2.342307</td>\n",
       "      <td>-1.411066</td>\n",
       "      <td>-1.403647</td>\n",
       "      <td>1.289200</td>\n",
       "      <td>1.003028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.000003</td>\n",
       "      <td>-1.480696</td>\n",
       "      <td>-2.416054</td>\n",
       "      <td>-5.304194</td>\n",
       "      <td>-5.594147</td>\n",
       "      <td>-3.821509</td>\n",
       "      <td>-2.972553</td>\n",
       "      <td>-1.150749</td>\n",
       "      <td>-3.847781</td>\n",
       "      <td>-5.653365</td>\n",
       "      <td>...</td>\n",
       "      <td>2.391880</td>\n",
       "      <td>3.338955</td>\n",
       "      <td>3.659802</td>\n",
       "      <td>-3.558969</td>\n",
       "      <td>-3.373843</td>\n",
       "      <td>-2.483952</td>\n",
       "      <td>-1.341713</td>\n",
       "      <td>-1.354084</td>\n",
       "      <td>1.215890</td>\n",
       "      <td>1.012855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.013108</td>\n",
       "      <td>-1.433146</td>\n",
       "      <td>-2.370693</td>\n",
       "      <td>-5.195253</td>\n",
       "      <td>-5.449184</td>\n",
       "      <td>-3.649208</td>\n",
       "      <td>-2.872211</td>\n",
       "      <td>-1.152749</td>\n",
       "      <td>-3.883492</td>\n",
       "      <td>-5.716038</td>\n",
       "      <td>...</td>\n",
       "      <td>2.332327</td>\n",
       "      <td>3.311926</td>\n",
       "      <td>3.543324</td>\n",
       "      <td>-3.563579</td>\n",
       "      <td>-3.443695</td>\n",
       "      <td>-2.428574</td>\n",
       "      <td>-1.336819</td>\n",
       "      <td>-1.392588</td>\n",
       "      <td>1.251609</td>\n",
       "      <td>0.991150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5.921699</td>\n",
       "      <td>-1.283766</td>\n",
       "      <td>-2.383720</td>\n",
       "      <td>-5.282466</td>\n",
       "      <td>-5.472414</td>\n",
       "      <td>-3.638901</td>\n",
       "      <td>-3.004997</td>\n",
       "      <td>-1.182681</td>\n",
       "      <td>-3.992485</td>\n",
       "      <td>-5.757446</td>\n",
       "      <td>...</td>\n",
       "      <td>2.466254</td>\n",
       "      <td>3.370398</td>\n",
       "      <td>3.597534</td>\n",
       "      <td>-3.587475</td>\n",
       "      <td>-3.316177</td>\n",
       "      <td>-2.475245</td>\n",
       "      <td>-1.326737</td>\n",
       "      <td>-1.392443</td>\n",
       "      <td>1.317529</td>\n",
       "      <td>1.009781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5.915044</td>\n",
       "      <td>-1.380411</td>\n",
       "      <td>-2.398464</td>\n",
       "      <td>-5.376094</td>\n",
       "      <td>-5.586296</td>\n",
       "      <td>-3.699112</td>\n",
       "      <td>-2.972688</td>\n",
       "      <td>-1.304089</td>\n",
       "      <td>-3.904057</td>\n",
       "      <td>-5.800055</td>\n",
       "      <td>...</td>\n",
       "      <td>2.338291</td>\n",
       "      <td>3.410264</td>\n",
       "      <td>3.603810</td>\n",
       "      <td>-3.587106</td>\n",
       "      <td>-3.400107</td>\n",
       "      <td>-2.456704</td>\n",
       "      <td>-1.360514</td>\n",
       "      <td>-1.475780</td>\n",
       "      <td>1.274439</td>\n",
       "      <td>1.003436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5.888218</td>\n",
       "      <td>-1.443362</td>\n",
       "      <td>-2.485135</td>\n",
       "      <td>-5.216915</td>\n",
       "      <td>-5.400325</td>\n",
       "      <td>-3.792253</td>\n",
       "      <td>-2.842944</td>\n",
       "      <td>-1.227707</td>\n",
       "      <td>-3.973413</td>\n",
       "      <td>-5.683228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.460209</td>\n",
       "      <td>3.463386</td>\n",
       "      <td>3.607751</td>\n",
       "      <td>-3.637353</td>\n",
       "      <td>-3.400398</td>\n",
       "      <td>-2.440771</td>\n",
       "      <td>-1.261816</td>\n",
       "      <td>-1.316931</td>\n",
       "      <td>1.304167</td>\n",
       "      <td>0.966489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5.944789</td>\n",
       "      <td>-1.434583</td>\n",
       "      <td>-2.520535</td>\n",
       "      <td>-5.280103</td>\n",
       "      <td>-5.458074</td>\n",
       "      <td>-3.732604</td>\n",
       "      <td>-2.835600</td>\n",
       "      <td>-1.136480</td>\n",
       "      <td>-3.899536</td>\n",
       "      <td>-5.732790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.322930</td>\n",
       "      <td>3.481045</td>\n",
       "      <td>3.551971</td>\n",
       "      <td>-3.574706</td>\n",
       "      <td>-3.305188</td>\n",
       "      <td>-2.484364</td>\n",
       "      <td>-1.273411</td>\n",
       "      <td>-1.433111</td>\n",
       "      <td>1.307770</td>\n",
       "      <td>1.019353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6.034562</td>\n",
       "      <td>-1.326249</td>\n",
       "      <td>-2.479582</td>\n",
       "      <td>-5.285128</td>\n",
       "      <td>-5.453748</td>\n",
       "      <td>-3.708537</td>\n",
       "      <td>-2.994405</td>\n",
       "      <td>-1.316749</td>\n",
       "      <td>-3.975543</td>\n",
       "      <td>-5.652202</td>\n",
       "      <td>...</td>\n",
       "      <td>2.352410</td>\n",
       "      <td>3.424680</td>\n",
       "      <td>3.629839</td>\n",
       "      <td>-3.531226</td>\n",
       "      <td>-3.433571</td>\n",
       "      <td>-2.346898</td>\n",
       "      <td>-1.361297</td>\n",
       "      <td>-1.357158</td>\n",
       "      <td>1.176148</td>\n",
       "      <td>1.001483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    5.992211 -1.458556 -2.522877 -5.227287 -5.570132 -3.687603 -2.891251   \n",
       "1    5.875168 -1.301533 -2.525220 -5.253348 -5.428700 -3.745577 -2.865036   \n",
       "2    5.960074 -1.473065 -2.406000 -5.350232 -5.436769 -3.739717 -2.846821   \n",
       "3    6.000003 -1.480696 -2.416054 -5.304194 -5.594147 -3.821509 -2.972553   \n",
       "4    6.013108 -1.433146 -2.370693 -5.195253 -5.449184 -3.649208 -2.872211   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "103  5.921699 -1.283766 -2.383720 -5.282466 -5.472414 -3.638901 -3.004997   \n",
       "104  5.915044 -1.380411 -2.398464 -5.376094 -5.586296 -3.699112 -2.972688   \n",
       "105  5.888218 -1.443362 -2.485135 -5.216915 -5.400325 -3.792253 -2.842944   \n",
       "106  5.944789 -1.434583 -2.520535 -5.280103 -5.458074 -3.732604 -2.835600   \n",
       "107  6.034562 -1.326249 -2.479582 -5.285128 -5.453748 -3.708537 -2.994405   \n",
       "\n",
       "          7         8         9    ...       105       106       107  \\\n",
       "0   -1.200210 -3.843001 -5.680121  ...  2.364161  3.452805  3.652766   \n",
       "1   -1.285238 -4.030012 -5.692140  ...  2.324138  3.390716  3.693698   \n",
       "2   -1.299774 -4.036907 -5.791673  ...  2.349994  3.386184  3.633986   \n",
       "3   -1.150749 -3.847781 -5.653365  ...  2.391880  3.338955  3.659802   \n",
       "4   -1.152749 -3.883492 -5.716038  ...  2.332327  3.311926  3.543324   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "103 -1.182681 -3.992485 -5.757446  ...  2.466254  3.370398  3.597534   \n",
       "104 -1.304089 -3.904057 -5.800055  ...  2.338291  3.410264  3.603810   \n",
       "105 -1.227707 -3.973413 -5.683228  ...  2.460209  3.463386  3.607751   \n",
       "106 -1.136480 -3.899536 -5.732790  ...  2.322930  3.481045  3.551971   \n",
       "107 -1.316749 -3.975543 -5.652202  ...  2.352410  3.424680  3.629839   \n",
       "\n",
       "          108       109       110       111       112       113       114  \n",
       "0   -3.619643 -3.314694 -2.345685 -1.343511 -1.340704  1.304490  1.016670  \n",
       "1   -3.592282 -3.355905 -2.350062 -1.397841 -1.332435  1.358238  0.986324  \n",
       "2   -3.685507 -3.364069 -2.342307 -1.411066 -1.403647  1.289200  1.003028  \n",
       "3   -3.558969 -3.373843 -2.483952 -1.341713 -1.354084  1.215890  1.012855  \n",
       "4   -3.563579 -3.443695 -2.428574 -1.336819 -1.392588  1.251609  0.991150  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "103 -3.587475 -3.316177 -2.475245 -1.326737 -1.392443  1.317529  1.009781  \n",
       "104 -3.587106 -3.400107 -2.456704 -1.360514 -1.475780  1.274439  1.003436  \n",
       "105 -3.637353 -3.400398 -2.440771 -1.261816 -1.316931  1.304167  0.966489  \n",
       "106 -3.574706 -3.305188 -2.484364 -1.273411 -1.433111  1.307770  1.019353  \n",
       "107 -3.531226 -3.433571 -2.346898 -1.361297 -1.357158  1.176148  1.001483  \n",
       "\n",
       "[108 rows x 115 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame()\n",
    "epochs = 200\n",
    "\n",
    "start = time.time()\n",
    "for i in range(0, epochs):\n",
    "    print('iteration: ', i)\n",
    "    display(res)\n",
    "    pertubated_initial_point = initial_point + np.random.uniform(-0.1, 0.1, ansatz.num_parameters)\n",
    "    \n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        estimator=Estimator(),\n",
    "        observables=GLOBAL_OPERATOR,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters\n",
    "    )\n",
    "\n",
    "    model = TorchConnector(qnn, initial_weights=pertubated_initial_point)\n",
    "\n",
    "    loss_function = nn.L1Loss() #This is MAE loss\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=0.05)\n",
    "\n",
    "    loss, weight = sampleWeightLoss(\n",
    "        model, \n",
    "        X_train_t,\n",
    "        y_train_t,\n",
    "        optimizer = optimizer, \n",
    "        loss_function = loss_function\n",
    "        )\n",
    "    res = pd.concat([res, pd.DataFrame(np.append(weight.numpy(), loss.numpy())).transpose()], ignore_index=True) \n",
    "    clear_output(wait=True)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "pd.DataFrame(res).astype('float').to_csv(f'{LOG_PATH}/{METHOD_TAG}/LossFunctionSurface.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print run statistics\n",
    "print(f'{device} Fit\\n'+\n",
    "      f'\\tQubits:\\t\\t{len(ansatz.qubits)}\\n'+\n",
    "      f'\\tId Blocks:\\t\\t{MAX_IDENTITIES_BLOCKS}\\n'+\n",
    "      f'\\tWeights:\\t{len(ansatz.parameters)}\\n'+\n",
    "      f'\\tEpochs:\\t\\t{epochs})\\n'+\n",
    "      f'\\tTime:\\t\\t{elapsed:0.2f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dataset (only the first two args)\n",
    "for x, y_target in zip(X_train_t, y_train_t):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], color=\"blue\", marker=\".\", markersize=5)\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], color=\"green\", marker=\".\", markersize=5)\n",
    "plt.xlabel('PC 0')\n",
    "plt.ylabel('PC 1')\n",
    "plt.show()\n",
    "\n",
    "rows_b = np.where(np.array(y_train_t)==1)\n",
    "rows_g = np.where(np.array(y_train_t)==-1)\n",
    "print('Blue:', y_train_t[rows_b].size())\n",
    "print('Green:', y_train_t[rows_g].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dataset (only the first and the third arg)\n",
    "for x, y_target in zip(X_train_t, y_train_t):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[2], color=\"blue\", marker=\".\", markersize=5)\n",
    "    else:\n",
    "        plt.plot(x[0], x[2], color=\"green\", marker=\".\", markersize=5)\n",
    "plt.xlabel('PC 0')\n",
    "plt.ylabel('PC 2')\n",
    "plt.show()\n",
    "\n",
    "rows_b = np.where(np.array(y_train_t)==1)\n",
    "rows_g = np.where(np.array(y_train_t)==-1)\n",
    "print('Blue:', y_train_t[rows_b].size())\n",
    "print('Green:', y_train_t[rows_g].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = featureMapGenerator(FEATURE_DIM)\n",
    "identity_block = preTrainedBlockGenerator(MAX_QUBITS_CLASSIFICATION, MAX_IDENTITIES_BLOCKS, overlay=IDENTITY_BLOCKS_OVERLAY, entanglement=ENTANGLEMENT, insert_barriers=True)\n",
    "ansatz = identity_block['circuit']\n",
    "qc=circuitBuilder(feature_map, ansatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute on multiple machines concurrently\n",
    "# Select separate sub-lists of instance numbers and run\n",
    "# Alternatively use range(MAX_INST) for all\n",
    "\n",
    "m = METHOD_TAG\n",
    "path = LOG_PATH\n",
    "times = []\n",
    "\n",
    "# for i in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: \n",
    "for i in [4, 5]: \n",
    "    \n",
    "    # Mark that the method's data has been saved\n",
    "    if (exists(f'{path}/{m}')):\n",
    "        print(f'Adding a new instance {i} of method {m}\\n')\n",
    "    else:\n",
    "        makedirs(f'{path}/{m}')\n",
    "        print(f'Creating the first instance {i} of method {m}\\n')\n",
    "\n",
    "    m3_variances = sampleM3Var()\n",
    "        \n",
    "    # The identity block returns parameters in order different to that in the ansatz\n",
    "    identity_block = preTrainedBlockGenerator(MAX_QUBITS_CLASSIFICATION, MAX_IDENTITIES_BLOCKS, overlay=IDENTITY_BLOCKS_OVERLAY, entanglement=ENTANGLEMENT, insert_barriers=True)\n",
    "    id_dict = {k.name : v for k, v in identity_block['params_values'].items()}\n",
    "    initial_point = [id_dict[p.name] for p in list(ansatz.parameters)]\n",
    "\n",
    "    # By default this will run as a local simulation\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        estimator=Estimator(),\n",
    "        observables=GLOBAL_OPERATOR,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters\n",
    "    )\n",
    "\n",
    "    model = TorchConnector(qnn, initial_weights=initial_point)\n",
    "\n",
    "    loss_function = nn.L1Loss() # MSELoss()\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=0.05)\n",
    "\n",
    "    start = time.time()\n",
    "    model, losses, accuracy_train, accuracy_test, weights = train(\n",
    "        model, \n",
    "        MAX_ITER, \n",
    "        X_train_t,\n",
    "        y_train_t,\n",
    "        X_val_t,\n",
    "        y_val_t,\n",
    "        optimizer = optimizer, \n",
    "        loss_function = loss_function\n",
    "        )\n",
    "    elapsed = time.time() - start\n",
    "    times.append(elapsed)\n",
    "\n",
    "    pd.DataFrame(m3_variances, num_qubits).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Variances.csv')\n",
    "    pd.DataFrame(losses).astype('float').to_csv(f'{path}/{m}/{m}-{i}-LossFunction.csv')\n",
    "    pd.DataFrame(accuracy_train).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Scores-Train.csv')\n",
    "    pd.DataFrame(accuracy_test).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Scores-Test.csv')\n",
    "    pd.DataFrame(weights).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Weights.csv')\n",
    "    \n",
    "    # Mark that the method's data has been saved\n",
    "    if (exists(f'{path}/{m}/{m}-Method.csv')):\n",
    "        f = open(f'{path}/{m}/{m}-Method.csv', 'a')\n",
    "    else:\n",
    "        f = open(f'{path}/{m}/{m}-Method.csv', 'w')\n",
    "        f.write(f'{m},Instance,Max Inst,Examples,Features,Iterations\\n')\n",
    "    f.write(f',{i},{MAX_INST},{DATA_SIZE},{FEATURE_DIM},{MAX_ITER}\\n')\n",
    "    f.close()\n",
    "    \n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nAverage time / instance: {np.average(times)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Plot the loss of the last saved instance\n",
    "plot_method_data([pd.DataFrame(losses).astype('float').T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss of the last saved instance\n",
    "plot_method_data([pd.DataFrame(accuracy_test).astype('float').T],\n",
    "                title='Test Accuracy', dlabel='inst#', xlabel='Accuraccy', ylabel='Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a13c8f5b783206a43b73a673b4c249a5e5ee0a2cf865a54b80fb656bbdf8626"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
