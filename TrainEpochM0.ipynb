{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Variational Quantum Models with Barren Plateaus Mitigation Strategies\n",
    "*Training QNN treated with method 0 (General) of the BP mitigation strategy (Cancer)*\n",
    "\n",
    "**Authors:**\n",
    "- Jacob Cybulski and Thanh Nguyen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.fake_provider import FakeAlmadenV2, FakeSherbrooke\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit.primitives import Estimator, BackendEstimator\n",
    "from qiskit_algorithms.gradients import ParamShiftEstimatorGradient\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from Components.train import *\n",
    "from Components.data import cancer_data\n",
    "from Components.circuits import *\n",
    "from Components.gradients import *\n",
    "from Components.utils import *\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config for all experiments (data size, feature dim etc.) is stored here\n",
    "from GLOBAL_CONFIG import *\n",
    "# Remember to tag the method\n",
    "METHOD_TAG = 'm0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend = FakeSherbrooke()\n",
    "# estimator = BackendEstimator(backend)\n",
    "estimator = Estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 398 samples\n",
      "Testing set: 171 samples\n",
      "Number of features: 4\n",
      "PCA Explained variance: [4.43782605e+05 7.31010006e+03 7.03833742e+02 5.46487379e+01]\n",
      "Classes:[0 1]; Encoded as: [-1  1]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = cancer_data(PCA_n = FEATURE_DIM)\n",
    "# X_train, X_val, y_train, y_val = fetch_mnist(PCA_n = FEATURE_DIM, data_size=DATA_SIZE)\n",
    "# X_train, X_val, y_train, y_val = iris(pd=False, PCA_n=None)\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train).to(torch.float32)\n",
    "y_train_t = torch.from_numpy(y_train).to(torch.float32)\n",
    "X_val_t = torch.from_numpy(X_val).to(torch.float32)\n",
    "y_val_t = torch.from_numpy(y_val).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found save folder: ./Logs-Cancer-v4/m0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (exists(f'{LOG_PATH}/{METHOD_TAG}')):\n",
    "    print(f'Found save folder: {LOG_PATH}/{METHOD_TAG}\\n')\n",
    "else:\n",
    "    makedirs(f'{LOG_PATH}/{METHOD_TAG}')\n",
    "    print(f'Creating save folder: {LOG_PATH}/{METHOD_TAG}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Gradient Variance Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use in the fist phase\n",
    "\n",
    "num_qubits = list(range(2, MAX_QUBITS))\n",
    "\n",
    "# Globak operator for all ansatzes, measure all qubits\n",
    "G_O = [SparsePauliOp.from_list([('Z'*n, 1)]) for n in num_qubits]\n",
    "\n",
    "# Local operator for all ansatzes, measere 2 last qubits\n",
    "L_O = [SparsePauliOp.from_list([('I' * (n - 2)+'Z'*2, 1)]) for n in num_qubits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = num_qubits\n",
    "ansatzes_m0 = [AnsatzGenerator(n, r) for n, r in zip(num_qubits, reps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleM0Var():\n",
    "    gradients_m0 = sampleAnsatz(estimator, ansatzes_m0, G_O)\n",
    "    variance = getVariance(gradients_m0, num_qubits)\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = featureMapGenerator(FEATURE_DIM)\n",
    "ansatz = AnsatzGenerator(MAX_QUBITS_CLASSIFICATION, MAX_REPS, ENTANGLEMENT)\n",
    "qc = circuitBuilder(feature_map, ansatz)\n",
    "initial_point = np.random.uniform(-np.pi, np.pi, ansatz.num_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CPU'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Find what devices are available\n",
    "from qiskit_aer.backends import AerSimulator\n",
    "devices = AerSimulator().available_devices()\n",
    "devices\n",
    "\n",
    "# Force CPU - PyTorch+Qiskit too slow with GPU\n",
    "devices = ('CPU')\n",
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: CPU\n"
     ]
    }
   ],
   "source": [
    "from qiskit.primitives import Estimator # For \"CPU\", ignores device=\"GPU\" option\n",
    "from qiskit_aer.primitives import Estimator as AerEstimator # For device=\"GPU\" option\n",
    "\n",
    "seed = 2023\n",
    "\n",
    "# Use GPU when present, otherwise CPU\n",
    "if 'GPU' in devices:\n",
    "    device = 'GPU'\n",
    "    estimator = AerEstimator(\n",
    "        backend_options={'seed_simulator': seed, 'method': 'statevector', \n",
    "                         'device' : device, 'cuStateVec_enable' : True},\n",
    "        run_options={'seed': seed, 'shots': 1000},\n",
    "        transpile_options={\"seed_transpiler\": seed},\n",
    "    )\n",
    "else:\n",
    "    device = 'CPU'\n",
    "    estimator = Estimator()\n",
    "    estimator.set_options(method='statevector')\n",
    "    estimator.set_options(device=device)\n",
    "    estimator.set_options(seed=seed)\n",
    "    estimator.options\n",
    "\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.294625</td>\n",
       "      <td>3.470296</td>\n",
       "      <td>3.988837</td>\n",
       "      <td>-0.071799</td>\n",
       "      <td>6.157076</td>\n",
       "      <td>-5.925570</td>\n",
       "      <td>-0.240510</td>\n",
       "      <td>-5.420621</td>\n",
       "      <td>2.183617</td>\n",
       "      <td>-5.123744</td>\n",
       "      <td>...</td>\n",
       "      <td>4.134838</td>\n",
       "      <td>3.591937</td>\n",
       "      <td>-5.721453</td>\n",
       "      <td>1.244283</td>\n",
       "      <td>-1.182275</td>\n",
       "      <td>4.014524</td>\n",
       "      <td>1.549098</td>\n",
       "      <td>4.176782</td>\n",
       "      <td>3.854430</td>\n",
       "      <td>1.023330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-2.758336</td>\n",
       "      <td>0.205612</td>\n",
       "      <td>-4.483027</td>\n",
       "      <td>1.456330</td>\n",
       "      <td>-1.421583</td>\n",
       "      <td>0.122751</td>\n",
       "      <td>-6.153173</td>\n",
       "      <td>-3.134696</td>\n",
       "      <td>2.658652</td>\n",
       "      <td>-1.362074</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.744651</td>\n",
       "      <td>4.997049</td>\n",
       "      <td>2.811939</td>\n",
       "      <td>-4.405932</td>\n",
       "      <td>5.414923</td>\n",
       "      <td>0.745130</td>\n",
       "      <td>3.596332</td>\n",
       "      <td>0.462827</td>\n",
       "      <td>1.844943</td>\n",
       "      <td>0.995920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2.883348</td>\n",
       "      <td>-6.127062</td>\n",
       "      <td>-0.290063</td>\n",
       "      <td>3.857682</td>\n",
       "      <td>-0.764765</td>\n",
       "      <td>4.392303</td>\n",
       "      <td>1.059665</td>\n",
       "      <td>4.387305</td>\n",
       "      <td>-0.778640</td>\n",
       "      <td>2.735846</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.337201</td>\n",
       "      <td>-0.688527</td>\n",
       "      <td>-5.380302</td>\n",
       "      <td>5.391607</td>\n",
       "      <td>0.776889</td>\n",
       "      <td>-4.216718</td>\n",
       "      <td>-3.289769</td>\n",
       "      <td>-4.370538</td>\n",
       "      <td>-3.722671</td>\n",
       "      <td>1.002387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.570989</td>\n",
       "      <td>-4.522782</td>\n",
       "      <td>0.131824</td>\n",
       "      <td>3.475224</td>\n",
       "      <td>0.114071</td>\n",
       "      <td>1.512406</td>\n",
       "      <td>6.241561</td>\n",
       "      <td>-2.426849</td>\n",
       "      <td>0.713442</td>\n",
       "      <td>0.538014</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.294670</td>\n",
       "      <td>4.696625</td>\n",
       "      <td>-5.732056</td>\n",
       "      <td>-1.243507</td>\n",
       "      <td>-4.092880</td>\n",
       "      <td>1.107100</td>\n",
       "      <td>-1.732219</td>\n",
       "      <td>-1.819028</td>\n",
       "      <td>-4.920787</td>\n",
       "      <td>0.976441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.309621</td>\n",
       "      <td>-4.818481</td>\n",
       "      <td>-1.201147</td>\n",
       "      <td>-0.289475</td>\n",
       "      <td>6.036474</td>\n",
       "      <td>-2.644164</td>\n",
       "      <td>-1.392959</td>\n",
       "      <td>2.844092</td>\n",
       "      <td>3.433517</td>\n",
       "      <td>3.924470</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.039738</td>\n",
       "      <td>-0.583746</td>\n",
       "      <td>5.984866</td>\n",
       "      <td>2.884353</td>\n",
       "      <td>5.896280</td>\n",
       "      <td>-4.332192</td>\n",
       "      <td>-2.843135</td>\n",
       "      <td>-6.200965</td>\n",
       "      <td>3.180139</td>\n",
       "      <td>0.974043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "194  1.294625  3.470296  3.988837 -0.071799  6.157076 -5.925570 -0.240510   \n",
       "195 -2.758336  0.205612 -4.483027  1.456330 -1.421583  0.122751 -6.153173   \n",
       "196  2.883348 -6.127062 -0.290063  3.857682 -0.764765  4.392303  1.059665   \n",
       "197 -0.570989 -4.522782  0.131824  3.475224  0.114071  1.512406  6.241561   \n",
       "198  1.309621 -4.818481 -1.201147 -0.289475  6.036474 -2.644164 -1.392959   \n",
       "\n",
       "          7         8         9    ...       95        96        97   \\\n",
       "194 -5.420621  2.183617 -5.123744  ...  4.134838  3.591937 -5.721453   \n",
       "195 -3.134696  2.658652 -1.362074  ... -2.744651  4.997049  2.811939   \n",
       "196  4.387305 -0.778640  2.735846  ... -5.337201 -0.688527 -5.380302   \n",
       "197 -2.426849  0.713442  0.538014  ... -5.294670  4.696625 -5.732056   \n",
       "198  2.844092  3.433517  3.924470  ... -2.039738 -0.583746  5.984866   \n",
       "\n",
       "          98        99        100       101       102       103       104  \n",
       "194  1.244283 -1.182275  4.014524  1.549098  4.176782  3.854430  1.023330  \n",
       "195 -4.405932  5.414923  0.745130  3.596332  0.462827  1.844943  0.995920  \n",
       "196  5.391607  0.776889 -4.216718 -3.289769 -4.370538 -3.722671  1.002387  \n",
       "197 -1.243507 -4.092880  1.107100 -1.732219 -1.819028 -4.920787  0.976441  \n",
       "198  2.884353  5.896280 -4.332192 -2.843135 -6.200965  3.180139  0.974043  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "for i in range(0, 200):\n",
    "    print('iteration: ', i)\n",
    "    display(res.tail())\n",
    "    point = np.random.uniform(-np.pi*2, np.pi*2, ansatz.num_parameters)\n",
    "    \n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        estimator=estimator,\n",
    "        observables=GLOBAL_OPERATOR,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters\n",
    "    )\n",
    "\n",
    "    model = TorchConnector(qnn, initial_weights=point)\n",
    "\n",
    "    loss_function = nn.L1Loss() #This is MAE loss\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=0.05)\n",
    "\n",
    "    loss, weight = sampleWeightLoss(\n",
    "        model, \n",
    "        X_train_t,\n",
    "        y_train_t,\n",
    "        optimizer = optimizer, \n",
    "        loss_function = loss_function\n",
    "        )\n",
    "    res = pd.concat([res, pd.DataFrame(np.append(weight.numpy(), loss.numpy())).transpose()], ignore_index=True) \n",
    "    clear_output(wait=True)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "pd.DataFrame(res).astype('float').to_csv(f'{LOG_PATH}/{METHOD_TAG}/LossFunctionSurface.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print run statistics\n",
    "print(f'{device} Fit\\n'+\n",
    "      f'\\tQubits:\\t\\t{num_qubits}\\n'+\n",
    "      f'\\tReps:\\t\\t{reps}\\n'+\n",
    "      f'\\tWeights:\\t{len(ansatz.parameters)}\\n'+\n",
    "      f'\\tEpochs:\\t\\t{epochs})\\n'+\n",
    "      f'\\tTime:\\t\\t{elapsed:0.2f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dataset (only the first two args)\n",
    "for x, y_target in zip(X_train_t, y_train_t):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], color=\"blue\", marker=\".\", markersize=5)\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], color=\"green\", marker=\".\", markersize=5)\n",
    "plt.xlabel('PC 0')\n",
    "plt.ylabel('PC 1')\n",
    "plt.show()\n",
    "\n",
    "rows_b = np.where(np.array(y_train_t)==1)\n",
    "rows_g = np.where(np.array(y_train_t)==-1)\n",
    "print('Blue:', y_train_t[rows_b].size())\n",
    "print('Green:', y_train_t[rows_g].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dataset (only the first and the third arg)\n",
    "for x, y_target in zip(X_train_t, y_train_t):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[2], color=\"blue\", marker=\".\", markersize=5)\n",
    "    else:\n",
    "        plt.plot(x[0], x[2], color=\"green\", marker=\".\", markersize=5)\n",
    "plt.xlabel('PC 0')\n",
    "plt.ylabel('PC 2')\n",
    "plt.show()\n",
    "\n",
    "rows_b = np.where(np.array(y_train_t)==1)\n",
    "rows_g = np.where(np.array(y_train_t)==-1)\n",
    "print('Blue:', y_train_t[rows_b].size())\n",
    "print('Green:', y_train_t[rows_g].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = featureMapGenerator(FEATURE_DIM)\n",
    "ansatz = AnsatzGenerator(MAX_QUBITS_CLASSIFICATION, MAX_REPS, ENTANGLEMENT)\n",
    "qc = circuitBuilder(feature_map, ansatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute on multiple machines concurrently\n",
    "# Select separate sub-lists of instance numbers and run\n",
    "# Alternatively use range(MAX_INST) for all\n",
    "\n",
    "m = METHOD_TAG\n",
    "path = LOG_PATH\n",
    "times = []\n",
    "\n",
    "# for i in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: \n",
    "for i in [0, 1]: \n",
    "     \n",
    "    # Mark that the method's data has been saved\n",
    "    if (exists(f'{path}/{m}')):\n",
    "        print(f'Adding a new instance {i} of method {m}\\n')\n",
    "    else:\n",
    "        makedirs(f'{path}/{m}')\n",
    "        print(f'Creating the first instance {i} of method {m}\\n')\n",
    "\n",
    "    m0_variances = sampleM0Var()\n",
    "        \n",
    "    # By default this will run as a local simulation\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        estimator=estimator,\n",
    "        observables=GLOBAL_OPERATOR,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters\n",
    "    )\n",
    "\n",
    "    # By default random initialisation\n",
    "    model = TorchConnector(qnn)\n",
    "\n",
    "    loss_function = nn.L1Loss() # nn.MSELoss()\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), lr=0.05)\n",
    "\n",
    "    start = time.time()\n",
    "    model, losses, accuracy_train, accuracy_test, weights = train(\n",
    "        model, \n",
    "        MAX_ITER, \n",
    "        X_train_t,\n",
    "        y_train_t,\n",
    "        X_val_t,\n",
    "        y_val_t,\n",
    "        optimizer = optimizer, \n",
    "        loss_function = loss_function\n",
    "        )\n",
    "    elapsed = time.time() - start\n",
    "    times.append(elapsed)\n",
    "\n",
    "    pd.DataFrame(m0_variances, num_qubits).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Variances.csv')\n",
    "    pd.DataFrame(losses).astype('float').to_csv(f'{path}/{m}/{m}-{i}-LossFunction.csv')\n",
    "    pd.DataFrame(accuracy_train).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Scores-Train.csv')\n",
    "    pd.DataFrame(accuracy_test).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Scores-Test.csv')\n",
    "    pd.DataFrame(weights).astype('float').to_csv(f'{path}/{m}/{m}-{i}-Weights.csv')\n",
    "    \n",
    "    # Mark that the method's data has been saved\n",
    "    if (exists(f'{path}/{m}/{m}-Method.csv')):\n",
    "        f = open(f'{path}/{m}/{m}-Method.csv', 'a')\n",
    "    else:\n",
    "        f = open(f'{path}/{m}/{m}-Method.csv', 'w')\n",
    "        f.write(f'{m},Instance,Max Inst,Examples,Features,Iterations\\n')\n",
    "    f.write(f',{i},{MAX_INST},{DATA_SIZE},{FEATURE_DIM},{MAX_ITER}\\n')\n",
    "    f.close()\n",
    "    \n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nAverage time / instance: {np.average(times)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Plot the loss of the last saved instance\n",
    "plot_method_data([pd.DataFrame(losses).astype('float').T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss of the last saved instance\n",
    "plot_method_data([pd.DataFrame(accuracy_test).astype('float').T],\n",
    "                title='Test Accuracy', dlabel='inst#', xlabel='Accuraccy', ylabel='Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a13c8f5b783206a43b73a673b4c249a5e5ee0a2cf865a54b80fb656bbdf8626"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
